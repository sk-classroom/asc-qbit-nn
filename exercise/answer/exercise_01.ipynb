{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/sk-classroom/asc-qbit-nn/blob/main/exercise/exercise_01.ipynb)\n",
    "\n",
    "# Learning Logistic Regression with a 1-bit Neural Network \n",
    "\n",
    "\n",
    "In this exercise, we will learn how to train a 1-bit neural network to perform logistic regression using the bitnet library. \n",
    "\n",
    "\n",
    "# Preparation\n",
    "\n",
    "We will use the [bitnet library](https://github.com/kyegomez/BitNet), together with the standard Python stack.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install bitnet\n",
    "#! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitnet import *\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training 1-bit Neural Network \n",
    "\n",
    "\n",
    "## Task \n",
    "\n",
    "We will train a neural network to learn a logistic gate: \n",
    "\n",
    "| X1 | X2 | Y |\n",
    "|----|----|---|\n",
    "| 0  | 0  | 0 |\n",
    "| 0  | 1  | 0 |\n",
    "| 1  | 0  | 0 |\n",
    "| 1  | 1  | 1 |\n",
    "\n",
    "where X1 and X2 are the inputs, and Y is the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
    "output = torch.tensor(\n",
    "    [\n",
    "        [0.0],\n",
    "        [0.0],\n",
    "        [0.0],\n",
    "        [1.0],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a full-precision neural network\n",
    "\n",
    "Let us first verify that a full-precision neural network can learn a logistic gate.\n",
    "\n",
    "Our neural network should be composed of the following components: \n",
    "- We use 2 linear layers with ReLU activation, with 32 hidden neurons. \n",
    "- The output of the last layer should be passed through a sigmoid function. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define the model\n",
    "# Two linear layers with ReLU activation, followed by a sigmoid function.\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 1),\n",
    "    nn.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model using `torch.nn.BCELoss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 1039.93it/s, loss=0.000166]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# TODO Define the optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# TODO Define the loss\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# TODO Train the model\n",
    "n_iter = 1000\n",
    "pbar = tqdm(range(n_iter))\n",
    "\n",
    "for i in pbar:\n",
    "    optimizer.zero_grad()\n",
    "    y = model.forward(input)\n",
    "    loss = loss_fn(y, output)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    pbar.set_postfix({\"loss\": loss.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.050465e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.166855e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.350192e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.996909e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target     Predicted\n",
       "0     0.0  1.050465e-07\n",
       "1     0.0  2.166855e-04\n",
       "2     0.0  1.350192e-04\n",
       "3     1.0  9.996909e-01"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "y = model(input)\n",
    "y = y.detach().numpy().reshape(-1)\n",
    "\n",
    "pd.DataFrame({\"Target\": output.numpy().reshape(-1), \"Predicted\": y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a 1-bit neural network\n",
    "\n",
    "`bitnet` provides a `BitLinear` layer that can be used to train a 1-bit neural network. `BitLinear` can be used to replace `nn.Linear`. \n",
    "\n",
    "Let us now train a 1-bit neural network to learn a logistic gate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitnet\n",
    "\n",
    "# TODO: Define the model\n",
    "# Two linear layers with ReLU activation, followed by a sigmoid function.\n",
    "model_1bit = nn.Sequential(\n",
    "    bitnet.BitLinear(2, 32),\n",
    "    nn.ReLU(),\n",
    "    bitnet.BitLinear(32, 1),\n",
    "    nn.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:01<00:00, 909.73it/s, loss=0.632]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train the model\n",
    "from tqdm import tqdm\n",
    "\n",
    "# TODO Define the optimizer\n",
    "optimizer = optim.AdamW(model_1bit.parameters(), lr=0.001)\n",
    "\n",
    "# TODO Define the loss\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# TODO Train the model\n",
    "n_iter = 1000\n",
    "pbar = tqdm(range(n_iter))\n",
    "\n",
    "for i in pbar:\n",
    "    optimizer.zero_grad()\n",
    "    y = model_1bit.forward(input)\n",
    "    loss = loss_fn(y, output)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    pbar.set_postfix({\"loss\": loss.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.467516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.543533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target  Predicted\n",
       "0     0.0   0.500000\n",
       "1     0.0   0.448024\n",
       "2     0.0   0.467516\n",
       "3     1.0   0.543533"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model_1bit(input)\n",
    "y = y.detach().numpy().reshape(-1)\n",
    "\n",
    "pd.DataFrame({\"Target\": output.numpy().reshape(-1), \"Predicted\": y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why did 1-bit neural network fail to learn the logistic gate ðŸ¤”? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "applsoftcomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
